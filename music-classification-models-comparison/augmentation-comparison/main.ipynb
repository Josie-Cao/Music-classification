{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Classification: Data Augmentation Techniques Comparison\n",
    "\n",
    "This notebook provides an interactive interface for comparing different data augmentation techniques for music genre classification.\n",
    "\n",
    "## Features\n",
    "- Configurable model architecture and training parameters\n",
    "- 5 different augmentation strategies\n",
    "- 5-fold cross-validation with statistical analysis\n",
    "- Comprehensive visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modular components\n",
    "from models import MusicGenreCNN, create_default_cnn, create_lightweight_cnn\n",
    "from training import TrainingConfig, get_quick_config, get_production_config\n",
    "from data import prepare_cv_data, MusicGenreDataset, print_data_summary\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Experiment Parameters\n",
    "\n",
    "Easily adjust training parameters, model architecture, and experiment settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your configuration\n",
    "# Options: get_quick_config(), get_production_config(), TrainingConfig()\n",
    "\n",
    "# For quick testing (recommended for first run)\n",
    "config = get_quick_config()\n",
    "\n",
    "# For production training (uncomment to use)\n",
    "# config = get_production_config()\n",
    "\n",
    "# Custom configuration (modify as needed)\n",
    "# config = TrainingConfig(\n",
    "#     num_epochs=100,\n",
    "#     patience=20,\n",
    "#     batch_size=32,\n",
    "#     learning_rate=0.001,\n",
    "#     dropout_rate=0.5,\n",
    "#     conv_channels=[32, 64, 128, 256],\n",
    "#     fc_units=[1024, 256]\n",
    "# )\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "print(f\"  Patience: {config.patience}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Dropout rate: {config.dropout_rate}\")\n",
    "print(f\"  Conv channels: {config.conv_channels}\")\n",
    "print(f\"  FC units: {config.fc_units}\")\n",
    "print(f\"  CV folds: {config.n_folds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare cross-validation data\n",
    "print(\"Preparing data for cross-validation...\")\n",
    "\n",
    "all_images, all_labels, cv_splits, genre_to_idx, idx_to_genre = prepare_cv_data(\n",
    "    config.data_dir, \n",
    "    n_folds=config.n_folds\n",
    ")\n",
    "\n",
    "# Print comprehensive data summary\n",
    "print_data_summary(all_images, all_labels, cv_splits, idx_to_genre)\n",
    "\n",
    "# Update config with actual number of classes\n",
    "config.num_classes = len(genre_to_idx)\n",
    "print(f\"\\nUpdated num_classes to: {config.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample model to inspect architecture\n",
    "sample_model = MusicGenreCNN(\n",
    "    num_classes=config.num_classes,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    conv_channels=config.conv_channels,\n",
    "    fc_units=config.fc_units,\n",
    "    input_size=config.input_size\n",
    ")\n",
    "\n",
    "model_info = sample_model.get_model_info()\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"  Input size: {model_info['input_size']}\")\n",
    "print(f\"  Conv channels: {model_info['conv_channels']}\")\n",
    "print(f\"  FC units: {model_info['fc_units']}\")\n",
    "print(f\"  Dropout rate: {model_info['dropout_rate']}\")\n",
    "print(f\"  Total parameters: {model_info['total_parameters']:,}\")\n",
    "print(f\"  Trainable parameters: {model_info['trainable_parameters']:,}\")\n",
    "\n",
    "# Clean up\n",
    "del sample_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiment\n",
    "\n",
    "This cell will run the complete cross-validation experiment. \n",
    "**Note: This may take several hours depending on your configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main experiment runner\n",
    "# We'll create a simplified version that uses our modular components\n",
    "\n",
    "# For now, let's run a single fold as an example\n",
    "print(\"Running a single fold example...\")\n",
    "print(\"(Full cross-validation will be implemented in the training module)\")\n",
    "\n",
    "# Get first fold data\n",
    "train_val_indices, test_indices = cv_splits[0]\n",
    "\n",
    "print(f\"Fold 1:\")\n",
    "print(f\"  Train+Val samples: {len(train_val_indices)}\")\n",
    "print(f\"  Test samples: {len(test_indices)}\")\n",
    "\n",
    "# This is where the full experiment would run\n",
    "print(\"\\n‚úì Example fold setup completed.\")\n",
    "print(\"\\nTo run the full experiment:\")\n",
    "print(\"1. Import and use the ModelTrainer class\")\n",
    "print(\"2. Or run the updated main.py file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Model Test\n",
    "\n",
    "Test the model with a small batch to ensure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test model\n",
    "test_model = MusicGenreCNN(\n",
    "    num_classes=config.num_classes,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    conv_channels=config.conv_channels,\n",
    "    fc_units=config.fc_units\n",
    ").to(device)\n",
    "\n",
    "# Create a dummy batch\n",
    "dummy_batch = torch.randn(4, 3, 256, 384).to(device)  # Batch of 4 images\n",
    "\n",
    "# Test forward pass\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = test_model(dummy_batch)\n",
    "\n",
    "print(f\"Input shape: {dummy_batch.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output classes: {output.shape[1]}\")\n",
    "print(\"‚úì Model forward pass successful!\")\n",
    "\n",
    "# Clean up\n",
    "del test_model, dummy_batch, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parameter Exploration\n",
    "\n",
    "Experiment with different configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different model architectures\n",
    "architectures = {\n",
    "    'Lightweight': {'conv_channels': [16, 32, 64, 128], 'fc_units': [512, 128]},\n",
    "    'Default': {'conv_channels': [32, 64, 128, 256], 'fc_units': [1024, 256]},\n",
    "    'Deep': {'conv_channels': [32, 64, 128, 256, 512], 'fc_units': [2048, 512, 256]}\n",
    "}\n",
    "\n",
    "print(\"Model Architecture Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, arch in architectures.items():\n",
    "    model = MusicGenreCNN(\n",
    "        num_classes=config.num_classes,\n",
    "        conv_channels=arch['conv_channels'],\n",
    "        fc_units=arch['fc_units']\n",
    "    )\n",
    "    \n",
    "    info = model.get_model_info()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Parameters: {info['total_parameters']:,}\")\n",
    "    print(f\"  Conv layers: {len(arch['conv_channels'])}\")\n",
    "    print(f\"  FC layers: {len(arch['fc_units'])}\")\n",
    "    print()\n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "To run the complete experiment:\n",
    "\n",
    "1. **Use the training module**: Import `ModelTrainer` and run the full cross-validation\n",
    "2. **Run main.py**: Use the updated main.py file for automated execution  \n",
    "3. **Analyze results**: Use the analysis module for statistical analysis and visualization\n",
    "\n",
    "The modular structure allows you to:\n",
    "- Easily adjust parameters through the `TrainingConfig` class\n",
    "- Swap model architectures\n",
    "- Add new augmentation techniques\n",
    "- Customize training procedures\n",
    "- Extend analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úì Notebook setup complete!\")\n",
    "print(\"\\nModule structure:\")\n",
    "print(\"  üìÅ models/ - Model architectures\")\n",
    "print(\"  üìÅ data/ - Data processing and augmentation\")\n",
    "print(\"  üìÅ training/ - Training configuration and procedures\")\n",
    "print(\"  üìÅ analysis/ - Statistical analysis and visualization\")\n",
    "print(\"  üìÅ utils/ - Common utilities\")\n",
    "print(\"\\nTo run full experiment: python main.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}